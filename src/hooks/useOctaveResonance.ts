import { useRef, useEffect, useCallback } from 'react';

export interface ResonanceSettings {
    trimStart: number;      // Seconds to cut from start (Attack removal)
    fadeInDuration: number; // Seconds for fade-in
    fadeInCurve: number;    // Exponential factor (1 = linear, 5 = very steep)
    delayTime: number;      // Seconds to delay playback (Latency)
    masterGain: number;     // Volume of the harmonic
}

// Global Cache for AudioBuffers (Persists across component unmounts)
const globalAudioBuffers = new Map<string, AudioBuffer>();

interface UseOctaveResonanceProps {
    getAudioContext?: () => AudioContext | null;
    getMasterGain?: () => GainNode | null;
}

export const useOctaveResonance = ({ getAudioContext, getMasterGain }: UseOctaveResonanceProps = {}) => {
    // We no longer strictly need a local ref if we use the getter, 
    // but for fallback we might still want one? 
    // Actually, to fix the mobile issue, we should AVOID creating a local context if one is supplied.
    const localAudioContextRef = useRef<AudioContext | null>(null);

    // Helper to get the active context (Shared or Local)
    const getContext = useCallback(() => {
        if (getAudioContext) {
            const ctx = getAudioContext();
            if (ctx) return ctx;
        }
        return localAudioContextRef.current;
    }, [getAudioContext]);

    // Initialize Local AudioContext ONLY if no shared getter is provided (Legacy fallback)
    useEffect(() => {
        if (!getAudioContext) {
            const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
            if (AudioContextClass) {
                localAudioContextRef.current = new AudioContext();
            }
        }
        return () => {
            if (localAudioContextRef.current) {
                localAudioContextRef.current.close().catch(e => console.warn("Failed to close AC", e));
            }
        };
    }, [getAudioContext]);

    // Load Audio Buffer (Global Cache)
    const loadBuffer = useCallback(async (noteName: string) => {
        // Return existing from Global Cache if available
        if (globalAudioBuffers.has(noteName)) {
            return globalAudioBuffers.get(noteName)!;
        }

        const ctx = getContext();
        if (!ctx) return null;

        try {
            const fileName = noteName.replace('#', '%23'); // Simple manual encode for #
            const response = await fetch(`/sounds/${fileName}.mp3`);
            const arrayBuffer = await response.arrayBuffer();

            // decoding audio data requires a context
            const audioBuffer = await ctx.decodeAudioData(arrayBuffer);

            globalAudioBuffers.set(noteName, audioBuffer);
            return audioBuffer;
        } catch (error) {
            console.error(`Failed to load resonance audio: ${noteName}`, error);
            return null;
        }
    }, [getContext]);

    const playResonantNote = useCallback(async (noteName: string, settings: ResonanceSettings) => {
        // â˜… [ë””ë²„ê·¸] ëª¨ë°”ì¼ í™˜ê²½ íŠ¹í™” í•˜ëª¨ë‹‰ ì¬ìƒ ë””ë²„ê¹…
        const isMobileDevice = typeof navigator !== 'undefined' && /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        const playStart = performance.now();
        console.log(`[Debug-Resonance] ===== í•˜ëª¨ë‹‰ ì¬ìƒ ì‹œì‘: ${noteName} =====`);
        console.log(`[Debug-Resonance] í™˜ê²½: ${isMobileDevice ? 'ğŸ“± ëª¨ë°”ì¼' : 'ğŸ’» ë°ìŠ¤í¬í†±'}`);

        const ctx = getContext();
        if (!ctx) {
            console.warn(`[Debug-Resonance] âš ï¸ AudioContext ì—†ìŒ!`);
            return;
        }

        console.log(`[Debug-Resonance] AudioContext ìƒíƒœ: ${ctx.state}`);
        console.log(`[Debug-Resonance] AudioContext sampleRate: ${ctx.sampleRate}Hz`);
        console.log(`[Debug-Resonance] AudioContext currentTime: ${ctx.currentTime.toFixed(4)}s`);
        console.log(`[Debug-Resonance] AudioContext baseLatency: ${ctx.baseLatency ?? 'N/A'}s`);

        if (ctx.state === 'suspended') {
            console.log(`[Debug-Resonance] AudioContext resume ì‹œë„...`);
            const resumeStart = performance.now();
            await ctx.resume();
            console.log(`[Debug-Resonance] AudioContext resume ì™„ë£Œ: ${(performance.now() - resumeStart).toFixed(1)}ms`);
        }

        // ë²„í¼ ë¡œë”© ì‹œê°„ ì¸¡ì •
        const bufferStart = performance.now();
        const buffer = await loadBuffer(noteName);
        const bufferLoadTime = performance.now() - bufferStart;

        if (!buffer) {
            console.warn(`[Debug-Resonance] âš ï¸ ë²„í¼ ë¡œë“œ ì‹¤íŒ¨: ${noteName}`);
            return;
        }

        console.log(`[Debug-Resonance] ë²„í¼ ë¡œë“œ: ${bufferLoadTime.toFixed(1)}ms (ìºì‹œ ${bufferLoadTime < 1 ? 'HIT âœ…' : 'MISS âŒ'})`);
        console.log(`[Debug-Resonance] ë²„í¼ ê¸¸ì´: ${buffer.duration.toFixed(2)}s, ì±„ë„: ${buffer.numberOfChannels}`);

        const source = ctx.createBufferSource();
        source.buffer = buffer;

        const gainNode = ctx.createGain();
        source.connect(gainNode);

        const masterGain = getMasterGain ? getMasterGain() : null;
        console.log(`[Debug-Resonance] Master Gain ì—°ê²°: ${masterGain ? 'âœ… Limiter ê²½ìœ ' : 'âŒ destination ì§ì ‘'}`);

        if (masterGain) {
            gainNode.connect(masterGain);
        } else {
            gainNode.connect(ctx.destination);
        }

        const now = ctx.currentTime;
        const startTime = now + settings.delayTime;

        // â˜… [ìˆ˜ì •ë¨] í´ë¦­ ë°©ì§€ë¥¼ ìœ„í•œ ë¯¸ë‹ˆ ë¨í”„ ì‹œê°„ (2ms)
        const ANTI_CLICK_RAMP_TIME = 0.002;

        console.log(`[Debug-Resonance] [ìŠ¤ì¼€ì¤„ë§]`);
        console.log(`[Debug-Resonance]   ctx.currentTime: ${now.toFixed(4)}s`);
        console.log(`[Debug-Resonance]   startTime: ${startTime.toFixed(4)}s (delay: ${settings.delayTime}s)`);
        console.log(`[Debug-Resonance]   trimStart: ${settings.trimStart}s`);
        console.log(`[Debug-Resonance]   fadeIn: ${settings.fadeInDuration}s (curve: ${settings.fadeInCurve})`);
        console.log(`[Debug-Resonance]   targetGain: ${settings.masterGain}`);
        console.log(`[Debug-Resonance]   antiClickRamp: ${ANTI_CLICK_RAMP_TIME * 1000}ms`);

        // â˜… [ìˆ˜ì •ë¨] Gain Ramp - í´ë¦­ ë°©ì§€ ë¡œì§ ì ìš©
        // ë¬¸ì œ: setValueAtTime(0, T)ì™€ linearRampToValueAtTime(0.01, T)ê°€ ê°™ì€ ì‹œê°„ì— ì˜ˆì•½ë˜ë©´ í´ë¦­ ë°œìƒ
        // í•´ê²°: linearRampê°€ 2ms í›„ë¡œ ì˜ˆì•½ë˜ë„ë¡ ìˆ˜ì •
        console.log(`[Debug-Resonance] â˜…â˜…â˜… Gain Ramp ì‹œì‘ (ìˆ˜ì •ëœ ë¡œì§) â˜…â˜…â˜…`);

        // 1. ì‹œì‘ ì‹œì ì— ì™„ì „ ë¬´ìŒ ì„¤ì •
        gainNode.gain.setValueAtTime(0, startTime);
        console.log(`[Debug-Resonance]   setValueAtTime(0, ${startTime.toFixed(4)})`);

        if (settings.fadeInCurve > 1) {
            // 2. 2msì— ê±¸ì³ 0 â†’ 0.01ë¡œ ë¶€ë“œëŸ½ê²Œ ì „í™˜ (í´ë¦­ ë°©ì§€)
            const miniRampEnd = startTime + ANTI_CLICK_RAMP_TIME;
            gainNode.gain.linearRampToValueAtTime(0.01, miniRampEnd);
            console.log(`[Debug-Resonance]   âœ… linearRamp(0.01, ${miniRampEnd.toFixed(4)}) - 2ms ì˜¤í”„ì…‹ ì ìš©`);

            // 3. ì´í›„ ì§€ìˆ˜ ê³¡ì„ ìœ¼ë¡œ ëª©í‘œ ë³¼ë¥¨ê¹Œì§€ í˜ì´ë“œì¸
            const fadeEndTime = miniRampEnd + settings.fadeInDuration;
            gainNode.gain.exponentialRampToValueAtTime(settings.masterGain, fadeEndTime);
            console.log(`[Debug-Resonance]   exponentialRamp(${settings.masterGain}, ${fadeEndTime.toFixed(4)})`);
        } else {
            // ì„ í˜• ë¨í”„: ì‹œì‘ë¶€í„° ë°”ë¡œ ëª©í‘œ ë³¼ë¥¨ê¹Œì§€
            const fadeEndTime = startTime + ANTI_CLICK_RAMP_TIME + settings.fadeInDuration;
            gainNode.gain.linearRampToValueAtTime(0.01, startTime + ANTI_CLICK_RAMP_TIME);
            gainNode.gain.linearRampToValueAtTime(settings.masterGain, fadeEndTime);
            console.log(`[Debug-Resonance]   linearRamp(${settings.masterGain}, ${fadeEndTime.toFixed(4)})`);
        }

        source.start(startTime, settings.trimStart);
        console.log(`[Debug-Resonance]   source.start(${startTime.toFixed(4)}, ${settings.trimStart}) í˜¸ì¶œë¨`);

        const totalTime = performance.now() - playStart;
        console.log(`[Debug-Resonance] ì´ ì²˜ë¦¬ ì‹œê°„: ${totalTime.toFixed(1)}ms`);
        console.log(`[Debug-Resonance] ===== í•˜ëª¨ë‹‰ ì¬ìƒ ìŠ¤ì¼€ì¤„ ì™„ë£Œ =====`);
    }, [getContext, loadBuffer, getMasterGain]);

    // Smart Preloading Function
    const preloadNotes = useCallback(async (noteNames: string[]) => {
        // Initialize local if needed and no shared
        if (!getAudioContext && !localAudioContextRef.current) {
            const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
            if (AudioContextClass) {
                localAudioContextRef.current = new AudioContext();
            }
        }

        // Parallel loading without blocking
        noteNames.forEach(note => {
            // Only load if not already in global cache
            if (!globalAudioBuffers.has(note)) {
                loadBuffer(note).catch(err => console.warn(`[Resonance] Preload failed for ${note}`, err));
            }
        });
    }, [loadBuffer, getAudioContext]);

    return {
        playResonantNote,
        preloadNotes
    };
};
